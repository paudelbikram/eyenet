var sajilonet;(()=>{"use strict";var e={d:(t,i)=>{for(var a in i)e.o(i,a)&&!e.o(t,a)&&Object.defineProperty(t,a,{enumerable:!0,get:i[a]})},o:(e,t)=>Object.prototype.hasOwnProperty.call(e,t),r:e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}},t={};e.r(t),e.d(t,{ActivationFunction:()=>i,ArgumentType:()=>h,BinaryOperation:()=>c,BinaryStep:()=>n,Linear:()=>s,Matrix:()=>A,MatrixOperationType:()=>u,NeuralNet:()=>g,NeuralNetConfig:()=>p,OperationArgument:()=>w,ReLu:()=>o,Sigmoid:()=>r,Tanh:()=>l,TrainingConfig:()=>d,UnaryOperation:()=>T});class i{constructor(e,t,i){this.name=e,this.activate=t,this.deactivate=i}}class n extends i{constructor(){super("BinaryStep",(e=>e>=0?1:0),(e=>0))}}class r extends i{constructor(){super("Sigmoid",(e=>1/(1+Math.exp(-e))),(e=>e*(1-e)))}}class s extends i{constructor(){super("Linear",(e=>e),(e=>1))}}class o extends i{constructor(){super("ReLu",(e=>Math.max(0,e)),(e=>e>0?1:0))}}class l extends i{constructor(){super("Tanh",(e=>(Math.exp(e)-Math.exp(-e))/(Math.exp(e)-Math.exp(-e))),(e=>1-a**2))}}class d{static build(e,t){return new d(e,t)}constructor(e,t){this.learningRate=e,this.epoch=t}}class p{static build(e,t){return new p(e,t)}constructor(e,t){this.layers=e,this.activationFunction=t}}class h{static SCALAR=new h("SCALAR");static MATRIX=new h("MATRIX");static FUNCTION=new h("FUNCTION");constructor(e){this.name=e}}class c{constructor(e,t,i,a,n){this.leftOperationArgument=e,this.operationType=t,this.rightOperationArgument=i,this.resultingArgument=a,this.description=n}}class u{static DOT_PRODUCT=new u("DOT_PRODUCT");static ELEMENT_WISE_ADDITION=new u("ELEMENT_WISE_ADDITION");static ELEMENT_WISE_FUNCTION=new u("ELEMENT_WISE_FUNCTION");static ELEMENT_WISE_SUBSTRACTION=new u("ELEMENT_WISE_SUBSTRACTION");static ELEMENT_WISE_MULTIPLICATION=new u("ELEMENT_WISE_MULTIPLICATION");static SCALAR_MULTIPLICATION=new u("SCALAR_MULTIPLICATION");static SCALAR_SUBSTRACTION=new u("SCALAR_SUBSTRACTION");static SCALAR_ADDITION=new u("SCALAR_ADDITION");static TRANSPOSE=new u("TRANSPOSE");constructor(e){this.name=e}}class w{constructor(e,t,i){this.argumentName=e,this.argumentType=t,this.argumentValue=i}}class T{constructor(e,t,i,a){this.argument=e,this.operationType=t,this.resultingArgument=i,this.description=a}}class A{constructor(e,t){this.rows=parseInt(e),this.cols=parseInt(t),this.data=[];for(let e=0;e<this.rows;e++){this.data[e]=[];for(let t=0;t<this.cols;t++)this.data[e][t]=0}}static fromArray(e){let t=new A(e.length,1);for(let i=0;i<e.length;i++)t.data[i][0]=e[i];return t}static subtract(e,t){if(e.rows!==t.rows||e.cols!==t.cols)throw console.error("Can not substract matrices of different size"),new Error("Can not substract matrices of different size");let i=new A(e.rows,e.cols);for(let a=0;a<i.rows;a++)for(let n=0;n<i.cols;n++)i.data[a][n]=e.data[a][n]-t.data[a][n];return i}toArray(){let e=[];for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)e.push(this.data[t][i]);return e}randomize(){for(let e=0;e<this.rows;e++)for(let t=0;t<this.cols;t++)this.data[e][t]=2*Math.random()-1}add(e){if(e instanceof A){if(e.rows!==this.rows||e.cols!==this.cols)throw console.error("Can not add matrices of different size"),new Error("Can not add matrices of different size");for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)this.data[t][i]+=e.data[t][i]}else for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)this.data[t][i]+=e}static transpose(e){let t=new A(e.cols,e.rows);for(let i=0;i<e.rows;i++)for(let a=0;a<e.cols;a++)t.data[a][i]=e.data[i][a];return t}static dotProduct(e,t){if(e.cols!==t.rows)throw console.error("Size does not match up for dot product"),new Error("Size does not match up for dot product");let i=new A(e.rows,t.cols);for(let a=0;a<i.rows;a++)for(let n=0;n<i.cols;n++){let r=0;for(let i=0;i<e.cols;i++)r+=e.data[a][i]*t.data[i][n];i.data[a][n]=r}return i}multiply(e){if(e instanceof A){if(e.rows!==this.rows||e.cols!==this.cols)throw console.error("Can not multiply matrices of different size"),new Error("Can not multiply matrices of different size");for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)this.data[t][i]*=e.data[t][i]}else for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)this.data[t][i]*=e}map(e){for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++){let a=this.data[t][i];this.data[t][i]=e(a)}}static map(e,t){let i=new A(e.rows,e.cols);for(let a=0;a<e.rows;a++)for(let n=0;n<e.cols;n++){let r=e.data[a][n];i.data[a][n]=t(r)}return i}deepCopy(){let e=new A(this.rows,this.cols);for(let t=0;t<this.rows;t++)for(let i=0;i<this.cols;i++)e.data[t][i]=this.data[t][i];return e}print(){console.table(this.data)}}class g{constructor(e){if(e.layers.length<3)throw console.error("Neural Net needs at least 3 layers [input layer, hidden layer, and output layer]"),new Error("Neural Net needs at least 3 layers [input layer, hidden layer, and output layer]");this.inputNodes=e.layers[0],this.outputNodes=e.layers[e.layers.length-1],this.activationFunction=e.activationFunction,this.weights=[],this.bias=[],this.isTrained=!1;for(let t=0;t<e.layers.length-1;t++){let i=new A(e.layers[t+1],e.layers[t]);i.randomize(),this.weights.push(i);let a=new A(e.layers[t+1],1);a.randomize(),this.bias.push(a)}}deepCopyArrayOfMatrices(e){const t=[];for(let i=0;i<e.length;i++)t[i]=e[i].deepCopy();return t}predict(e,t=!1){let i=[],a=A.fromArray(e);for(let e=0;e<this.weights.length;e++){let n=[],r=a.deepCopy();a=A.dotProduct(this.weights[e],a);let s=a.deepCopy();t&&n.push(new c(new w("weight",h.MATRIX,this.weights[e].deepCopy()),u.DOT_PRODUCT,new w("X",h.MATRIX,r),new w("weight_DOT_PRODUCT_X",h.MATRIX,s),"Calculating Weighted Layer : Matrix Dot Product Between Weight And Input Matrix (X)")),a.add(this.bias[e]);let o=a.deepCopy();t&&n.push(new c(new w("weightedLayer",h.MATRIX,s),u.ELEMENT_WISE_ADDITION,new w("bias",h.MATRIX,this.bias[e].deepCopy()),new w("layerAfterBias",h.MATRIX,o),"Adding Bias To Weighted Layer : Matrix Element Wise Addition Between Weighted Layer And Bias")),a.map(this.activationFunction.activate),t&&n.push(new c(new w("activation",h.FUNCTION,this.activationFunction.activate.toString()),u.ELEMENT_WISE_FUNCTION,new w("layerAfterBias",h.MATRIX,o),new w("Y",h.MATRIX,a.deepCopy()),"Calculating Final Output : Activation Function To Each Element of Matrix (Output Of Layer After Adding Bias)")),i.push(n)}return t?[a.toArray(),i]:a.toArray()}fit(e,t,i=new Set){let a=new Map,n=new Set([0,1,2,e.length-3,e.length-2,e.length-1]);for(let r=0;r<t.epoch;r++){let s=this.deepCopyArrayOfMatrices(this.weights),o=this.deepCopyArrayOfMatrices(this.bias),l=new Map;for(let a=0;a<e.length;a++){let s=e[a],o=this.deepCopyArrayOfMatrices(this.weights),d=this.deepCopyArrayOfMatrices(this.bias),p=this.train(s.X,s.Y,t.learningRate);i.has(r)&&n.has(a)&&l.set(a,{weightBefore:o,biasBefore:d,feedforward:p.feedforward,backpropagation:p.backpropagation,weightAfter:this.deepCopyArrayOfMatrices(this.weights),biasAfter:this.deepCopyArrayOfMatrices(this.bias)})}i.has(r)&&a.set(r,{weightBefore:s,biasBefore:o,weightAfter:this.deepCopyArrayOfMatrices(this.weights),biasAfter:this.deepCopyArrayOfMatrices(this.bias),trainingData:l})}return this.isTrained=!0,a}train(e,t,i){let a=[],n=[],r=A.fromArray(e),s=[];s.push(r);for(let e=0;e<this.weights.length;e++){let t=[],i=A.dotProduct(this.weights[e],s[s.length-1]),n=i.deepCopy();t.push(new c(new w("weight",h.MATRIX,this.weights[e].deepCopy()),u.DOT_PRODUCT,new w("X",h.MATRIX,s[s.length-1].deepCopy()),new w("weight_DOT_PRODUCT_X",h.MATRIX,n),"Calculating Weighted Layer : Matrix Dot Product Between Weight And Input Matrix (X)")),i.add(this.bias[e]);let r=i.deepCopy();t.push(new c(new w("weightedInput",h.MATRIX,n),u.ELEMENT_WISE_ADDITION,new w("bias",h.MATRIX,this.bias[e].deepCopy()),new w("weightedInput_ADD_bias",h.MATRIX,r),"Adding Bias To Weighted Layer : Matrix Element Wise Addition Between Weighted Layer And Bias")),i.map(this.activationFunction.activate),t.push(new c(new w("activation",h.FUNCTION,this.activationFunction.activate.toString()),u.ELEMENT_WISE_FUNCTION,new w("inputWithBias",h.MATRIX,r),new w("activatedInput",h.MATRIX,i.deepCopy()),"Calculating Final Output : Activation Function To Each Element of Matrix (Output Of Layer After Adding Bias)")),a.push([t]),s.push(i)}let o=s[s.length-1],l=A.fromArray(t),d=A.subtract(l,o),p=[];p.push(new c(new w("Y",h.MATRIX,l.deepCopy()),u.ELEMENT_WISE_SUBSTRACTION,new w("calculatedY",h.MATRIX,o.deepCopy()),new w("error",h.MATRIX,d.deepCopy()),"Calculating Error : Matrix Element Wise Substraction Between Labeled Output (Y) AND Calculated Output")),n.push(p);let g=[],I=A.map(o,this.activationFunction.deactivate),C=I.deepCopy();g.push(new c(new w("deactivation",h.FUNCTION,this.activationFunction.deactivate.toString()),u.ELEMENT_WISE_FUNCTION,new w("calculatedY",h.MATRIX,o.deepCopy()),new w("gradient",h.MATRIX,C),"Calculating Gradient Step 1 : Deactivation Function To Each Element of Matrix (Calculated Output)")),I.multiply(d);let y=I.deepCopy();g.push(new c(new w("gradient",h.MATRIX,C),u.ELEMENT_WISE_MULTIPLICATION,new w("error",h.MATRIX,d.deepCopy()),new w("gradient_MULTIPLY_error",h.MATRIX,y),"Calculating Gradient Step 2 : Matrix Element Wise Multiplication Between Result Of Step 1 And Error")),I.multiply(i),g.push(new c(new w("gradientAfterError",h.MATRIX,y),u.SCALAR_MULTIPLICATION,new w("learningRate",h.SCALAR,i),new w("gradientAfterLearningRate",h.MATRIX,I.deepCopy()),"Calculating Gradient Step 3 (Final Step) : Matrix Scalar Multiplication Between Result of Step 2 And Learning Rate"));let M=A.transpose(s[s.length-2]);g.push(new T(new w("outputOfLastHiddenLayer",h.MATRIX,s[s.length-2].deepCopy()),u.TRANSPOSE,new w("TRANSPOSE_lastHiddenLayer",h.MATRIX,M.deepCopy()),"Calculating Transpose Of Last Hidden Layer : Matrix Transpose Of Output Of Last Hidden Layer"));let f=A.dotProduct(I,M);g.push(new c(new w("gradientAfterLearningRate",h.MATRIX,I.deepCopy()),u.DOT_PRODUCT,new w("transposeOfLastHiddenLayer",h.MATRIX,M.deepCopy()),new w("delta",h.MATRIX,f.deepCopy()),"Calculating Delta : Matrix Dot Product Between Gradient And Transpose Of Last Hidden Layer"));let E=this.weights[this.weights.length-1].deepCopy();this.weights[this.weights.length-1].add(f),g.push(new c(new w("weight",h.MATRIX,E),u.ELEMENT_WISE_ADDITION,new w("delta",h.MATRIX,f.deepCopy()),new w("newWeight",h.MATRIX,this.weights[this.weights.length-1].deepCopy()),"Calculating New Weight : Matrix Element Wise Addition Between Current Weight And Delta"));let O=this.bias[this.bias.length-1].deepCopy();this.bias[this.bias.length-1].add(I),g.push(new c(new w("bias",h.MATRIX,O),u.ELEMENT_WISE_ADDITION,new w("gradientAfterLearningRate",h.MATRIX,I.deepCopy()),new w("newBias",h.MATRIX,this.bias[this.bias.length-1].deepCopy()),"Calculating New Bias : Matrix Element Wise Addition Between Current Bias And Gradient")),n.push(g);let R=d;for(let e=this.weights.length-1;e>0;e--){let t=A.transpose(this.weights[e]),a=[];a.push(new T(new w("weight",h.MATRIX,this.weights[e].deepCopy()),u.TRANSPOSE,new w("transposeOfWeight",h.MATRIX,t.deepCopy()),"Calculating Transpose Of Current Weight : Matrix Transpose Of Current Weight"));let r=R.deepCopy();R=A.dotProduct(t,R),a.push(new c(new w("transposeOfWeight",h.MATRIX,t.deepCopy()),u.DOT_PRODUCT,new w("hiddenError",h.MATRIX,r.deepCopy()),new w("transposeOfWeight_DOT_hiddenError",h.MATRIX,R.deepCopy()),"Calculating DOT Product : Matrix DOT Product Between Transpose Of Current Weight And Error"));let o=A.map(s[e],this.activationFunction.deactivate),l=o.deepCopy();a.push(new c(new w("deactivation",h.FUNCTION,this.activationFunction.deactivate.toString()),u.ELEMENT_WISE_FUNCTION,new w("layerOutput",h.MATRIX,s[e].deepCopy()),new w("gradient",h.MATRIX,o.deepCopy()),"Calculating Gradient Step 1 : Deactivation Function To Each Element of Matrix (Current Output Layer)")),o.multiply(R);let d=o.deepCopy();a.push(new c(new w("hiddenGradient",h.MATRIX,l.deepCopy()),u.ELEMENT_WISE_MULTIPLICATION,new w("hiddenError",h.MATRIX,R.deepCopy()),new w("gradientAfterError",h.MATRIX,d),"Calculating Gradient Step 2 : Matrix Element Wise Multiplication Between Result Of Step 1 And Error")),o.multiply(i),a.push(new c(new w("gradientAfterError",h.MATRIX,d),u.SCALAR_MULTIPLICATION,new w("learningRate",h.SCALAR,i),new w("gradientAfterLearningRate",h.MATRIX,o.deepCopy()),"Calculating Gradient Step 3 (Final Step) : Matrix Scalar Multiplication Between Result of Step 2 And Learning Rate"));let p=A.transpose(s[e-1]);a.push(new T(new w("layerOutput",h.MATRIX,s[e-1].deepCopy()),u.TRANSPOSE,new w("transposeOfLayerOutput",h.MATRIX,p.deepCopy()),"Calculating Transpose Of Last Hidden Layer : Matrix Transpose Of Output Of Last Hidden Layer"));let g=A.dotProduct(o,p);a.push(new c(new w("hiddenGradient",h.MATRIX,o.deepCopy()),u.DOT_PRODUCT,new w("transposeOfLayerOutput",h.MATRIX,p.deepCopy()),new w("delta",h.MATRIX,g.deepCopy()),"Calculating Delta : Matrix Dot Product Between Gradient And Transpose Of Last Hidden Layer"));let I=this.weights[e-1].deepCopy(),C=this.bias[e-1].deepCopy();this.weights[e-1].add(g),a.push(new c(new w("previousWeight",h.MATRIX,I),u.ELEMENT_WISE_ADDITION,new w("delta",h.MATRIX,g.deepCopy()),new w("newWeight",h.MATRIX,this.weights[e-1].deepCopy()),"Calculating New Weight : Matrix Element Wise Addition Between Current Weight And Delta")),this.bias[e-1].add(o),a.push(new c(new w("previousBias",h.MATRIX,C),u.ELEMENT_WISE_ADDITION,new w("hiddenGradient",h.MATRIX,o.deepCopy()),new w("newBias",h.MATRIX,this.bias[e-1].deepCopy()),"Calculating New Bias : Matrix Element Wise Addition Between Current Bias And Gradient")),n.push(a)}return{feedforward:a,backpropagation:n}}}sajilonet=t})();